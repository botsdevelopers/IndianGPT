const express = require('express');
const {Configuration, OpenAIApi} = require("openai")
const socketio = require('socket.io');
const http = require('http');

const configuration = new Configuration({
  apiKey: process.env.token,
});
const openai = new OpenAIApi(configuration);
const app = express();
const server = http.createServer(app);
const io = socketio(server);
app.get("/", (req, res) => {
  res.render("main.ejs", {root: "."})
})
app.get("/api/v1/:id", async (req, res) => {
  let prompt = req.params.id
const response = await openai.createCompletion({
  model: "text-davinci-003",
  prompt: prompt,
  temperature: 0.5,
  max_tokens: 160,
  top_p: 1.0,
  frequency_penalty: 0.5,
  presence_penalty: 0.0,
});
  
res.send(response.data.choices[0].text)
console.log(response.data.choices[0].text)
})
io.on('connection', socket => {
  console.log('a user connected');

  socket.on('send message', message => {
    io.emit('message', message);
       openai.createCompletion({
  model: "text-davinci-003",
  prompt: `You: ${message} \n\n GPT: `,
  temperature: 0.5,
  max_tokens: 150,
  top_p: 1.0,
  frequency_penalty: 0.5,
  presence_penalty: 0.5,
})
    .then((response) => {
      // Send the response back to the client
     console.log(message)
    console.log(response.data.choices[0].text)
      socket.emit('message', `> ${response.data.choices[0].text}`);
  });
  });

  socket.on('disconnect', () => {
    console.log('user disconnected');
  });
});
app.get('*', function(req, res){
res.status(404).redirect('https://timecapsule.jatinsharma24.repl.co/upload')
})
const port = process.env.PORT || 0000;
server.listen(port, () => {
  console.log(`server listening on port ${port}`);
});
